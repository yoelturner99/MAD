{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18947,"status":"ok","timestamp":1702654951888,"user":{"displayName":"Yoel Turner","userId":"08667140368994491494"},"user_tz":-60},"id":"0tsz9-ZkFxXr","outputId":"344fe9fd-19c8-4600-a865-116603a0c4bb"},"outputs":[],"source":["import sys\n","# Check if we are in Google Colab\n","IN_COLAB = 'google.colab' in sys.modules\n","if IN_COLAB:\n","  from google.colab import drive\n","  # Mounting the Gdrive\n","  drive.mount('/content/drive', force_remount=True)\n","  GDRIVE_ROOT_DIR = '/content/drive/MyDrive'\n","  !pip install transformers\n","  !pip install sentencepiece"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":11643,"status":"ok","timestamp":1702654963520,"user":{"displayName":"Yoel Turner","userId":"08667140368994491494"},"user_tz":-60},"id":"a38mBOzwFN2D"},"outputs":[],"source":["import os\n","import time\n","import random\n","import argparse\n","from tqdm.notebook import tqdm\n","\n","import torch\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.metrics import matthews_corrcoef\n","from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from transformers import CamembertTokenizer, CamembertForSequenceClassification"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":58,"status":"ok","timestamp":1702654983784,"user":{"displayName":"Yoel Turner","userId":"08667140368994491494"},"user_tz":-60},"id":"nbOFI3CWFN2H"},"outputs":[],"source":["args_dict = {\n","    'data_path': 'KESKIA/data/limjiayi_hateful_memes_expanded_test.tsv',\n","    'model_dir': 'KESKIA/models/camembert_mad_test',\n","    'batch_size': 32,\n","    'num_labels': 2,\n","    'max_len': 64,\n","    'device_id': 0\n","}\n","\n","args = argparse.Namespace(**args_dict)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55,"status":"ok","timestamp":1702654983785,"user":{"displayName":"Yoel Turner","userId":"08667140368994491494"},"user_tz":-60},"id":"a-t47b4MFN2I","outputId":"db54e64c-be30-43a9-a488-0fa5772738c8"},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n","Device ID -> cuda:0\n"]}],"source":["# Check for GPU\n","if torch.cuda.is_available():\n","    # Tell PyTorch to use the GPU.\n","    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n","    print('We will use the GPU:', torch.cuda.get_device_name(args.device_id))\n","    device = torch.device(args.device_id)\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")\n","print(f'Device ID -> {device}')"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1702654983786,"user":{"displayName":"Yoel Turner","userId":"08667140368994491494"},"user_tz":-60},"id":"OH-_m2-4FN2I"},"outputs":[],"source":["# Fix Random Seed\n","SEED_VAL = 999\n","random.seed(SEED_VAL)\n","np.random.seed(SEED_VAL)\n","torch.manual_seed(SEED_VAL)\n","torch.cuda.manual_seed_all(SEED_VAL)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":907,"status":"ok","timestamp":1702654984675,"user":{"displayName":"Yoel Turner","userId":"08667140368994491494"},"user_tz":-60},"id":"iQItsVUgFN2J","outputId":"7a0abaa0-a871-45e9-a7ce-3f0d79fe2742"},"outputs":[{"name":"stdout","output_type":"stream","text":["Size of dataset: 3000\n","Maximum length of text: 216\n"]}],"source":["# Uploading data\n","if IN_COLAB:\n","  data_path = os.path.join(GDRIVE_ROOT_DIR, args.data_path)\n","else:\n","  data_path = args.data_path\n","\n","data = pd.read_csv(\n","  data_path,\n","  sep='\\t',\n","  on_bad_lines='skip'\n",")\n","print(f'Size of dataset: {len(data)}')\n","\n","text_list = data['text'].values[:]\n","label_list = data['label'].values[:]\n","\n","print(f'Maximum length of text: {max([len(t) for t in text_list])}')"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40374,"status":"ok","timestamp":1702655025037,"user":{"displayName":"Yoel Turner","userId":"08667140368994491494"},"user_tz":-60},"id":"OQJUGD4MFN2J","outputId":"fa8f12b1-50ff-41c0-df1f-2b26c44f919f"},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"text/plain":["CamembertForSequenceClassification(\n","  (roberta): CamembertModel(\n","    (embeddings): CamembertEmbeddings(\n","      (word_embeddings): Embedding(32005, 1024, padding_idx=1)\n","      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 1024)\n","      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): CamembertEncoder(\n","      (layer): ModuleList(\n","        (0-23): 24 x CamembertLayer(\n","          (attention): CamembertAttention(\n","            (self): CamembertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): CamembertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): CamembertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): CamembertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): CamembertClassificationHead(\n","    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=1024, out_features=2, bias=True)\n","  )\n",")"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Uploading model\n","if IN_COLAB:\n","  model_dir = os.path.join(GDRIVE_ROOT_DIR, args.model_dir)\n","else:\n","  model_dir = args.model_dir\n","\n","# Initializing tokenizer\n","tokenizer = CamembertTokenizer.from_pretrained(model_dir)\n","# Load Model\n","model = CamembertForSequenceClassification.from_pretrained(\n","    pretrained_model_name_or_path=model_dir, # Use the 12-layer CamemBERT\n","    num_labels=args.num_labels, # Binary classification.\n","    output_attentions=False, # Whether the model returns attentions weights.\n","    output_hidden_states=False, # Whether the model returns all hidden-states.\n",")\n","model.to(device)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":85,"status":"ok","timestamp":1702655025038,"user":{"displayName":"Yoel Turner","userId":"08667140368994491494"},"user_tz":-60},"id":"gjKsk0n-LAxv"},"outputs":[],"source":["input_ids = []\n","attention_masks = []\n","for text in text_list:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","        str(text),                  # Sentence to encode.\n","        add_special_tokens=True,    # Add '[CLS]' and '[SEP]'\n","        max_length=args.max_len,    # Set maximum length of sequence\n","        padding='max_length',       # Pad to max length\n","        truncation=True,            # Truncate to max length\n","        return_attention_mask=True, # Construct attn. masks.\n","        return_tensors='pt',        # Return pytorch tensors.\n","    )\n","\n","    # Add the encoded sentence to the list.\n","    input_ids.append(encoded_dict['input_ids'])\n","\n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":88,"status":"ok","timestamp":1702655025043,"user":{"displayName":"Yoel Turner","userId":"08667140368994491494"},"user_tz":-60},"id":"ULbLHNQJLp6n"},"outputs":[],"source":["# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(label_list)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":83,"status":"ok","timestamp":1702655025048,"user":{"displayName":"Yoel Turner","userId":"08667140368994491494"},"user_tz":-60},"id":"wPZR5UPxFN2M"},"outputs":[],"source":["# Create the DataLoader for our test set.\n","test_data = TensorDataset(input_ids, attention_masks, labels)\n","test_sampler = SequentialSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=args.batch_size)"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":82,"status":"ok","timestamp":1702655025049,"user":{"displayName":"Yoel Turner","userId":"08667140368994491494"},"user_tz":-60},"id":"w6CLGJWWFN2M"},"outputs":[],"source":["def test(model, test_dataloader, device, desc) -> float:\n","    # Put model in evaluation mode\n","    model.eval()\n","\n","    # Tracking variables\n","    predictions , true_labels = [], []\n","\n","    # Predict\n","    for batch in tqdm(test_dataloader,desc=desc):\n","        # Add batch to GPU\n","        batch = tuple(t.to(device) for t in batch)\n","\n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        # Telling the model not to compute or store gradients, saving memory and\n","        # speeding up prediction\n","        with torch.no_grad():\n","            # Forward pass, calculate logit predictions\n","            outputs = model(\n","                b_input_ids,\n","                token_type_ids=None,\n","                attention_mask=b_input_mask\n","            )\n","\n","        logits = outputs[0]\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Store predictions and true labels\n","        predictions.append(logits)\n","        true_labels.append(label_ids)\n","\n","    # Combine the predictions for each batch into a single list of 0s and 1s.\n","    flat_predictions = [item for sublist in predictions for item in sublist]\n","    flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","\n","    # Combine the correct labels for each batch into a single list.\n","    flat_true_labels = [item for sublist in true_labels for item in sublist]\n","\n","    return flat_predictions, flat_true_labels"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[" # Testing Model\n","tic = time.time()\n","pred, lab = test(\n","    model=model,\n","    test_dataloader=test_dataloader,\n","    device=device,\n","    desc=f'[{str(device).upper()}] Testing Model'\n",")\n","tt = (time.time() - tic)/60\n","print(f'Inference time for {len(lab)} sentences: {tt:.2f} mins')\n","# Average of the correct predictions\n","score = sum([x == y for x, y in zip(list(pred), lab)])/len(lab)\n","print(f'Accuracy score: {score*10:.2f} %')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0149530d55c642cfb1307b76ebe6dc33":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e653dca4046497d9e9cf4a89dd484f5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c20fa4f48a04febaec3b85d47f13d48":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7decdbf9ba6a412288995296cac8a22d","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8793d009c7544bf9a77ee34df5903ffb","value":4}},"40e63345cb5e405ba24fb886bb7be044":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6a0b35b1c92341f18fbe458381010590","IPY_MODEL_3c20fa4f48a04febaec3b85d47f13d48","IPY_MODEL_50c9d8b7795a4346b60990e61d4d0af6"],"layout":"IPY_MODEL_0e653dca4046497d9e9cf4a89dd484f5"}},"50c9d8b7795a4346b60990e61d4d0af6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0755bcb5a514809baaa5729b8be81fd","placeholder":"​","style":"IPY_MODEL_64c1992d4634412f9582fcb93499a88f","value":" 4/4 [00:01&lt;00:00,  2.88it/s]"}},"64c1992d4634412f9582fcb93499a88f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a0b35b1c92341f18fbe458381010590":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0149530d55c642cfb1307b76ebe6dc33","placeholder":"​","style":"IPY_MODEL_96f65b5e283944dbbe3156f1d353539f","value":"[CUDA:0] Testing Model: 100%"}},"7decdbf9ba6a412288995296cac8a22d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8793d009c7544bf9a77ee34df5903ffb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"96f65b5e283944dbbe3156f1d353539f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e0755bcb5a514809baaa5729b8be81fd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
